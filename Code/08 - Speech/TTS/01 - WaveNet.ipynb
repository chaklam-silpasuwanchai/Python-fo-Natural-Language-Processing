{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CausalConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    A 1D causal convolution layer that pads the input on the left.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation = dilation\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=0, dilation=dilation)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Compute the required padding for causal convolution.\n",
    "        padding = self.dilation * (self.kernel_size - 1)\n",
    "        # Pad only on the left (i.e. the beginning of the sequence)\n",
    "        x = F.pad(x, (padding, 0))\n",
    "        return self.conv(x)\n",
    "\n",
    "class WaveNetBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A single WaveNet residual block with a gated activation unit.\n",
    "    \"\"\"\n",
    "    def __init__(self, residual_channels, skip_channels, kernel_size, dilation):\n",
    "        super(WaveNetBlock, self).__init__()\n",
    "        # Two parallel causal convolutions for filter and gate.\n",
    "        self.filter_conv = CausalConv1d(residual_channels, residual_channels, kernel_size, dilation)\n",
    "        self.gate_conv   = CausalConv1d(residual_channels, residual_channels, kernel_size, dilation)\n",
    "        # 1x1 convolutions for residual and skip connections.\n",
    "        self.residual_conv = nn.Conv1d(residual_channels, residual_channels, kernel_size=1)\n",
    "        self.skip_conv     = nn.Conv1d(residual_channels, skip_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply dilated convolutions for filter and gate.\n",
    "        filter_out = torch.tanh(self.filter_conv(x))\n",
    "        gate_out = torch.sigmoid(self.gate_conv(x))\n",
    "        # Elementwise multiplication of filter and gate outputs.\n",
    "        out = filter_out * gate_out\n",
    "        # Create skip and residual outputs.\n",
    "        skip = self.skip_conv(out)\n",
    "        residual = self.residual_conv(out)\n",
    "        # Residual connection: add the block input back to the output.\n",
    "        residual = residual + x\n",
    "        return residual, skip\n",
    "\n",
    "class WaveNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A simplified WaveNet model that stacks multiple WaveNet blocks.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, residual_channels, skip_channels, end_channels,\n",
    "                 kernel_size, num_layers, dilation_cycle_length):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels (e.g. number of quantization channels).\n",
    "            residual_channels (int): Number of channels in the residual layers.\n",
    "            skip_channels (int): Number of channels in the skip connections.\n",
    "            end_channels (int): Number of channels in the post-processing layers.\n",
    "            kernel_size (int): Size of the convolutional kernel.\n",
    "            num_layers (int): Total number of WaveNet blocks.\n",
    "            dilation_cycle_length (int): Number of layers before dilation factors repeat.\n",
    "        \"\"\"\n",
    "        super(WaveNet, self).__init__()\n",
    "        # Initial 1x1 convolution to match channel dimensions.\n",
    "        self.input_conv = nn.Conv1d(in_channels, residual_channels, kernel_size=1)\n",
    "        self.blocks = nn.ModuleList()\n",
    "        # Create a series of WaveNet blocks with exponentially increasing dilations.\n",
    "        for i in range(num_layers):\n",
    "            dilation = 2 ** (i % dilation_cycle_length)\n",
    "            self.blocks.append(WaveNetBlock(residual_channels, skip_channels, kernel_size, dilation))\n",
    "        self.relu = nn.ReLU()\n",
    "        # Post-processing: 1x1 convolutions to produce final output logits.\n",
    "        self.output_conv1 = nn.Conv1d(skip_channels, end_channels, kernel_size=1)\n",
    "        self.output_conv2 = nn.Conv1d(end_channels, in_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch, channels, time).\n",
    "        Returns:\n",
    "            Tensor: Output logits over the quantized audio channels.\n",
    "        \"\"\"\n",
    "        x = self.input_conv(x)\n",
    "        skip_connections = []\n",
    "        # Process the input through each residual block.\n",
    "        for block in self.blocks:\n",
    "            x, skip = block(x)\n",
    "            skip_connections.append(skip)\n",
    "        # Sum all skip connection outputs.\n",
    "        out = sum(skip_connections)\n",
    "        out = self.relu(out)\n",
    "        out = self.output_conv1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output_conv2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 256, 16000])\n"
     ]
    }
   ],
   "source": [
    " # Example parameters (adjust these as needed)\n",
    "batch_size = 2\n",
    "# Suppose audio is quantized into 256 channels (e.g. Î¼-law quantization)\n",
    "in_channels = 256  \n",
    "sequence_length = 16000  # e.g., one second of audio at 16kHz\n",
    "model = WaveNet(in_channels=in_channels, residual_channels=32, skip_channels=32,\n",
    "                end_channels=32, kernel_size=2, num_layers=10, dilation_cycle_length=10)\n",
    "# Create a dummy input tensor (batch, channels, time)\n",
    "x = torch.randn(batch_size, in_channels, sequence_length)\n",
    "out = model(x)\n",
    "print(\"Output shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
