{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Word2Vec\n",
        "\n",
        "Let's work on skipgram-based implementation of word2vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Define some very simple data for understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\",\n",
        "                 \"dog cat animal\", \"cat animal dog\", \"cat dog animal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'animal', 'dog'],\n",
              " ['cat', 'dog', 'animal']]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = [sent.split(\" \") for sent in corpus]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'fruit', 'banana', 'animal', 'cat', 'dog']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'apple': 0, 'fruit': 1, 'banana': 2, 'animal': 3, 'cat': 4, 'dog': 5}\n"
          ]
        }
      ],
      "source": [
        "#numericalization\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "print(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "#vocab size\n",
        "voc_size = len(vocab)\n",
        "print(voc_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#append UNK\n",
        "vocab.append('<UNK>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'fruit', 'banana', 'animal', 'cat', 'dog', '<UNK>']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2index['<UNK>'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#just in case we need to use\n",
        "index2word = {v:k for k, v in word2index.items()} "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'fruit']\n",
            "['banana', 'apple', 'fruit']\n",
            "['banana', 'fruit', 'apple']\n",
            "['dog', 'cat', 'animal']\n",
            "['cat', 'animal', 'dog']\n",
            "['cat', 'dog', 'animal']\n"
          ]
        }
      ],
      "source": [
        "for c in corpus:\n",
        "    print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_batch(batch_size, word_sequence):\n",
        "    \n",
        "    # Make skip gram of one size window\n",
        "    skip_grams = []\n",
        "    # loop each word sequence\n",
        "    # we starts from 1 because 0 has no context\n",
        "    # we stop at second last for the same reason\n",
        "    for sent in corpus:\n",
        "        for i in range(1, len(sent) - 1):\n",
        "            target = word2index[sent[i]]\n",
        "            context = [word2index[sent[i - 1]], word2index[sent[i + 1]]]\n",
        "            for w in context:\n",
        "                skip_grams.append([target, w])\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) #randomly pick without replacement\n",
        "        \n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams[i][0]])  # target, e.g., 2\n",
        "        random_labels.append([skip_grams[i][1]])  # context word, e.g., 3\n",
        "            \n",
        "    return np.array(random_inputs), np.array(random_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  [[3]\n",
            " [0]]\n",
            "Target:  [[4]\n",
            " [2]]\n"
          ]
        }
      ],
      "source": [
        "#testing the method\n",
        "batch_size = 2 # mini-batch size\n",
        "input_batch, target_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "print(\"Input: \", input_batch)\n",
        "print(\"Target: \", target_batch)\n",
        "\n",
        "#we will convert them to tensor during training, so don't worry..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model\n",
        "\n",
        "$$J(\\theta) = -\\frac{1}{T}\\sum_{t=1}^{T}\\sum_{\\substack{-m \\leq j \\leq m \\\\ j \\neq 0}}\\log P(w_{t+j} | w_t; \\theta)$$\n",
        "\n",
        "where $P(w_{t+j} | w_t; \\theta) = $\n",
        "\n",
        "$$P(o|c)=\\frac{\\exp(\\mathbf{u_o^{\\top}v_c})}{\\sum_{w=1}^V\\exp(\\mathbf{u_w^{\\top}v_c})}$$\n",
        "\n",
        "where $o$ is the outside words and $c$ is the center word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Skipgram(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, emb_size):\n",
        "        super(Skipgram,self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, emb_size)\n",
        "        self.embedding_u = nn.Embedding(vocab_size, emb_size)\n",
        "    \n",
        "    def forward(self, center_words, target_words, all_vocabs):\n",
        "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
        "        all_embeds    = self.embedding_u(all_vocabs) #   [batch_size, voc_size, emb_size]\n",
        "        \n",
        "        scores      = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "\n",
        "        norm_scores = all_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, voc_size, emb_size] @ [batch_size, emb_size, 1] = [batch_size, voc_size, 1] = [batch_size, voc_size]\n",
        "\n",
        "        nll = -torch.mean(torch.log(torch.exp(scores)/torch.sum(torch.exp(norm_scores), 1).unsqueeze(1))) # log-softmax\n",
        "        # scalar (loss must be scalar)    \n",
        "            \n",
        "        return nll # negative log likelihood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size     = 2 # mini-batch size\n",
        "embedding_size = 2 #so we can later plot\n",
        "model          = Skipgram(voc_size, embedding_size)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 7])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def prepare_sequence(seq, word2index):\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return torch.LongTensor(idxs)\n",
        "\n",
        "#use for the normalized term in the probability calculation\n",
        "all_vocabs = prepare_sequence(list(vocab), word2index).expand(batch_size, len(vocab))  # [batch_size, voc_size]\n",
        "all_vocabs.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000 | cost: 1.601026 | time: 0m 0s\n",
            "Epoch: 2000 | cost: 1.254817 | time: 0m 0s\n",
            "Epoch: 3000 | cost: 1.240061 | time: 0m 0s\n",
            "Epoch: 4000 | cost: 1.127742 | time: 0m 0s\n",
            "Epoch: 5000 | cost: 1.287674 | time: 0m 0s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch = random_batch(batch_size, corpus)\n",
        "    input_batch  = torch.LongTensor(input_batch)  #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch) #[batch_size, 1]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = model(input_batch, target_batch, all_vocabs)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Plotting the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'fruit', 'banana', 'animal', 'cat', 'dog', '<UNK>']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#list of vocabs\n",
        "vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "word = vocab[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#numericalization\n",
        "id = word2index[word]\n",
        "id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_tensor = torch.LongTensor([id])\n",
        "id_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[-2.5259, -1.4863]], grad_fn=<EmbeddingBackward0>),\n",
              " tensor([[-0.2725,  0.5630]], grad_fn=<EmbeddingBackward0>))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get the embedding by averaging\n",
        "v_embed = model.embedding_v(id_tensor)\n",
        "u_embed = model.embedding_u(id_tensor)\n",
        "\n",
        "v_embed, u_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-0.4617, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#average to get the word embedding\n",
        "word_embed = (v_embed + u_embed) / 2\n",
        "word_embed[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's write a function to get embedding given a word\n",
        "def get_embed(word):\n",
        "    id_tensor = torch.LongTensor([word2index[word]])\n",
        "    v_embed = model.embedding_v(id_tensor)\n",
        "    u_embed = model.embedding_u(id_tensor) \n",
        "    word_embed = (v_embed + u_embed) / 2 \n",
        "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocab[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Cosine similarity\n",
        "\n",
        "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
        "\n",
        "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
        "\n",
        "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'fruit', 'banana', 'animal', 'cat', 'dog', '<UNK>']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's try similarity between first and second, and second and third\n",
        "cat          = get_embed('cat')\n",
        "fruit        = get_embed('fruit')\n",
        "animal       = get_embed('animal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  -0.9541749355631831\n",
            "cat vs. animal:  0.9853831297506683\n",
            "cat vs. cat:  1.0\n"
          ]
        }
      ],
      "source": [
        "#numpy version\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "    \n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  -0.954174935563183\n",
            "cat vs. animal:  0.9853831297506683\n",
            "cat vs. cat:  1\n"
          ]
        }
      ],
      "source": [
        "#scipy version\n",
        "from scipy import spatial\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n",
        "    return cos_sim\n",
        "\n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "dsai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f2c79af21be9d001248940c049b6176cf8bfb45cabf7aa85848f5cea0f590f6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
