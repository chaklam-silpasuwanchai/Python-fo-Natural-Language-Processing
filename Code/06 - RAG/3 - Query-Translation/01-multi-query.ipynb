{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiQueryRetreiver\n",
    "\n",
    "Distance-based vector database retrieval relies on high-dimensional space representations to find similar documents, but query wording changes and inadequate embeddings can lead to varying results. The MultiQueryRetriever automates prompt tuning by generating diverse queries from a user input, collecting relevant documents for each query, and combining the results to potentially overcome the limitations of distance-based retrieval and provide a more comprehensive set of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-groq\n",
    "!pip install langchain-openai\n",
    "!pip install langchain-core\n",
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set logging for the queries\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "llm = ChatGroq(model=\"meta-llama/llama-4-scout-17b-16e-instruct\")\n",
    "\n",
    "embedding_model = HuggingFaceBgeEmbeddings(\n",
    "    model_name = \"BAAI/bge-small-en-v1.5\",\n",
    "    model_kwargs = {'device':'cpu'},\n",
    "    encode_kwargs = {'normalize_embeddings':True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Scratch: Implementing Chunking Techniques for System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_template =\"\"\"\n",
    "You are an helpful assistant that generates multiple alternate search query out of user's input query.\n",
    "These alternate queries will be used to make simantic search within a vector database using  similariy metrics. \n",
    "Generate 5 alternate queries that can be formed to better understand user's input query given below\n",
    "\n",
    "{user_query}\n",
    "\n",
    "Strictly retrun only the alternate queries separated by new line \n",
    "\"\"\"\n",
    "\n",
    "multi_query_prompt = ChatPromptTemplate.from_template(multi_query_template)\n",
    "\n",
    "# Creating a chain\n",
    "\n",
    "multi_query_chain = (\n",
    "    multi_query_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: [i for i in x.split(\"\\n\") if x!=''])\n",
    ")\n",
    "\n",
    "# Generating Alternate Queries\n",
    "multi_query_chain.invoke(\"Suggest me items to sell in my new outdoor adventure and expedition utilities shop.\")\n",
    "\n",
    "# ['Outdoor adventure equipment shop inventory ideas',\n",
    "#  'Outdoor expedition gear store product suggestions',\n",
    "#  'Best selling items for an outdoor adventure shop',\n",
    "#  'Essential equipment for outdoor expeditions',\n",
    "#  'Products to stock in an outdoor adventure and expedition store']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Langchain : MultiQueryRetriever (Combine Query & Retrieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "db_file_name = './vectordb_path/ml-andrew-ng/'\n",
    "vectordb = FAISS.load_local(folder_path = db_file_name, embeddings  = embedding_model) \n",
    "retreiver = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=vectordb.as_retriever(), llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. How do Linear Regression and Logistic Regression differ from each other?', '2. In what ways do Linear Regression and Logistic Regression vary?', '3. Can you explain the distinctions between Linear Regression and Logistic Regression?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"What are the difference between Linear Regression and Logistic Regression?\"\n",
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It try to rephase the question in multiple ways and then use those rephrased queries to retrieve documents from the vector database. \n",
    "# This way it can capture different aspects of the question and retrieve a more diverse set of relevant documents.\n",
    "# 1. How do Linear Regression and Logistic Regression differ from each other?\n",
    "# 2. In what ways do Linear Regression and Logistic Regression vary?\n",
    "# 3. Can you explain the distinctions between Linear Regression and Logistic Regression?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
