{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0fff476",
   "metadata": {},
   "source": [
    "# [Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection](https://arxiv.org/pdf/2310.11511.pdf)\n",
    "\n",
    "Self-RAG is a framework that teaches a Large Language Model (LLM) to retrieve, generate, and critique its own text simultaneously. Unlike standard RAG, which retrieves documents blindly for every query, Self-RAG dynamically decides when to retrieve and how to use the information via special \"Reflection Tokens.\"\n",
    "\n",
    "Key Mechanisms:\n",
    "1. Adaptive Retrieval: The model predicts a [Retrieve] token to decide if external information is needed.\n",
    "2. Self-Critique: After retrieving and generating, the model evaluates itself using three critique tokens:\n",
    "   - [IsRel]: Are the retrieved documents relevant?\n",
    "   - [IsSup]: Is the generated answer supported by the documents?\n",
    "   - [IsUse]: Is the answer useful to the user?\n",
    "3. Critique-Aware Decoding: During inference, the system selects the best response sequence that maximizes the likelihood of positive critique tokens (e.g., selecting answers that are \"Supported\" and \"Useful\").\n",
    "\n",
    "Original Code : https://github.com/AkariAsai/self-rag\n",
    "\n",
    "\n",
    "<img src=\"../figures/self-rag.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bca3222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
