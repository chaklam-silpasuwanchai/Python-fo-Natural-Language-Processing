{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ad55e6-9d4c-43fd-a5ad-3dd6a9f9c8c7",
   "metadata": {},
   "source": [
    "# Name Entity Recognition (HuggingFace)\n",
    "\n",
    "Reference:  https://huggingface.co/learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8aa15f-5a16-4a36-a232-df4f025e5a9a",
   "metadata": {},
   "source": [
    "## 1. Load the data\n",
    "\n",
    "CoNLL-2003 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aef5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset('conll2003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18fa113c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c34196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e84a2c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b95b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"].features[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fa13186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_features = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "label_names  = ner_features.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e74043-e1e4-46a7-940a-b1ddd759cc30",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "\n",
    "Tokenization (numericalization), aligning labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fb0259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-cased\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83c36350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7786, 3776, 1110, 4106, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Deep learning is fun!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ed7dce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Deep learning is fun! [SEP]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([101, 7786, 3776, 1110, 4106, 106, 102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1beb684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast  #huggingface built-in tokenizer, that could basically perform very fast using some kind of parallel computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfa761b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = raw_datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e11d20ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "befa1ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(tokens, is_split_into_words=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c353a2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'EU',\n",
       " 'rejects',\n",
       " 'German',\n",
       " 'call',\n",
       " 'to',\n",
       " 'boycott',\n",
       " 'British',\n",
       " 'la',\n",
       " '##mb',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8f89b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f1e7554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2205b680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68c6f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    \n",
    "    for word_id in word_ids: #[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]\n",
    "        \n",
    "        if word_id != current_word:\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "            \n",
    "        elif word_id is None:\n",
    "            new_labels.append(-100) #-100 is a default index that HF will ignore\n",
    "            \n",
    "        else: \n",
    "            label = labels[word_id] #if the current token is the same word as the previous token\n",
    "            if label % 2 == 1:  #if the label is B-XXX, we change it to I-XXX\n",
    "                label += 1\n",
    "            new_labels.append(label)\n",
    "    \n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a274f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c35db9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = inputs.word_ids()\n",
    "word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73fc3961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "493c50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    \n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "        \n",
    "    tokenized_inputs['labels'] = new_labels\n",
    "    return  tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c79db3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4689f384e09b442aaede4e32d530c90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71eafdfd662546d283b987301b11a3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d864a6d8c223413bae2cbfe239ff8bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels, batched=True, remove_columns=raw_datasets[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e14fbbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8623cb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1943, 14428, 102]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][1]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44491bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Peter Blackburn [SEP]'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_datasets[\"train\"][1]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "605c3125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-100, 1, 2, -100]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][1]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bda154b-ea07-42ca-b18a-c3febf66ee73",
   "metadata": {},
   "source": [
    "## 3. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8717945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f83dc6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [tokenized_datasets[\"train\"][i] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa1e75bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input_ids': [101,\n",
       "   7270,\n",
       "   22961,\n",
       "   1528,\n",
       "   1840,\n",
       "   1106,\n",
       "   21423,\n",
       "   1418,\n",
       "   2495,\n",
       "   12913,\n",
       "   119,\n",
       "   102],\n",
       "  'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]},\n",
       " {'input_ids': [101, 1943, 14428, 102],\n",
       "  'token_type_ids': [0, 0, 0, 0],\n",
       "  'attention_mask': [1, 1, 1, 1],\n",
       "  'labels': [-100, 1, 2, -100]}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e2a4c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7270, 22961,  1528,  1840,  1106, 21423,  1418,  2495, 12913,\n",
       "           119,   102],\n",
       "        [  101,  1943, 14428,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0, -100],\n",
       "        [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100, -100]])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3aa53db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(tokenized_datasets[\"train\"], shuffle=True, collate_fn=data_collator, batch_size=8)\n",
    "val_loader   = DataLoader(tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879bb709-fbea-4aa6-a8be-b8d82e03165a",
   "metadata": {},
   "source": [
    "## 4. Model\n",
    "\n",
    "The second part of the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c947c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label ={str(i): label for i, label in enumerate(label_names)}\n",
    "label2id = {v:k for k, v in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8b6b3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    checkpoint, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508fe5ce-07d0-4b7a-abd2-869c88eb18d3",
   "metadata": {},
   "source": [
    "## 5. Metrics\n",
    "\n",
    "We need to define `compute_metrics()` that takes list of predictions and labels, and returns a dictionary with the metric names and values.\n",
    "\n",
    "Note: `pip install seqeval`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da40d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f3737f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d5a10a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label_names[i] for i in labels]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2369d920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels2 = labels.copy()\n",
    "labels2[2] = 'B-ORG'\n",
    "labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "616f514e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MISC': {'precision': 1.0,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 2},\n",
       " 'ORG': {'precision': 0.5,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 1},\n",
       " 'overall_precision': 0.6666666666666666,\n",
       " 'overall_recall': 0.6666666666666666,\n",
       " 'overall_f1': 0.6666666666666666,\n",
       " 'overall_accuracy': 0.8888888888888888}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=[labels2], references=[labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648605a1-e3b8-46cb-99a7-6333e58e9954",
   "metadata": {},
   "source": [
    "## 6. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90363a22-adde-4ea2-8cf5-8b837c0b733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "#Adam with learning decay\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972e8a3-ecac-4129-94b8-1ab61fd722f6",
   "metadata": {},
   "source": [
    "## 7. Accelerator\n",
    "\n",
    "So usually, you just train right..\n",
    "\n",
    "But huggingface creates a wrapper called `Accelerator` which\n",
    "utilize your resources in a parallel fashion...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b624dfe-82c6-48cb-b365-620cd540997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8fd2b28-3001-486b-a91c-cd3137bdc974",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "\n",
    "model, optimizer, train_loader, val_loader = \\\n",
    "    accelerator.prepare(model, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f1558-2929-4305-9796-512531cf61ef",
   "metadata": {},
   "source": [
    "## 8. Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35dbf2b1-60b4-4cda-8143-f2b999a4e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 1\n",
    "num_update_steps_per_epoch = len(train_loader)\n",
    "num_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede399a5-168b-4719-bb85-7a49aaca1867",
   "metadata": {},
   "source": [
    "## 9. Repository\n",
    "\n",
    "Repository is like a free-cloud space, hosted by HuggingFace.\n",
    "\n",
    "It is very useful because for every certain steps, it will upload\n",
    "your model to the Huggingface....if suddenly something crashes, \n",
    "you can resume....because your weights are push to Huggingface repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfa0c60e-c664-4b74-ba7e-ae9b100af037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd960099b894837aba411f9715d5374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "420cd6d9-ae73-42a0-8142-db81e0450db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chaklam/bert-finetuned-ner-accelerate'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import Repository, get_full_repo_name\n",
    "\n",
    "model_name = \"bert-finetuned-ner-accelerate\"\n",
    "repo_name  = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2f4a4484-87a8-4367-a17c-5d756ddf1531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaklam/Github/Natural-Language-Processing/.venv/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/Users/chaklam/Github/Natural-Language-Processing/Code/04 - Huggingface/code-along/bert-finetuned-ner-accelerate is already a clone of https://huggingface.co/Chaklam/bert-finetuned-ner-accelerate. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "#sudo apt install git-lfs\n",
    "#brew install git-lfs\n",
    "#go to git-lfs and download it\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "output_dir = \"bert-finetuned-ner-accelerate\"\n",
    "repo       = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d5ce8-103b-4970-b180-11d80246f641",
   "metadata": {},
   "source": [
    "## 10. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "70200178-5bb8-4176-ada7-aa24ead70ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert predictions and labels into strings, like \n",
    "#what our metric object expects\n",
    "\n",
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels      = labels.detach().cpu().clone().numpy()\n",
    "    \n",
    "    true_labels = [[label_names[l] for l in label if l !=-100] \n",
    "                   for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l!= - 100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4424de47-a2ac-48c5-adb1-11b851c07181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5018b8c47b79412bb5874fb871043e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm #progress bar\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_train_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        outputs = model(**batch) #** because our input is keyword (input_ids = ...)\n",
    "        loss    = outputs.loss\n",
    "        accelerator.backward(loss)  #instead of optimizer.backward\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    #evaluation\n",
    "    model.eval() #all batchnorm, dropout will be turned off....\n",
    "    for batch in val_loader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch) \n",
    "        \n",
    "        predictions = outputs.logits.argmax(dim = -1)\n",
    "        labels      = batch[\"labels\"]\n",
    "        \n",
    "        #necessary to pad predictions and labels to same length...if not...crash...\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n",
    "        labels      = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "        \n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered      = accelerator.gather(labels)\n",
    "        \n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "        \n",
    "    results = metric.compute()\n",
    "\n",
    "    print(\n",
    "\n",
    "        f\"epoch {epoch}: \",\n",
    "        {\n",
    "                key: results[f\"overall_{key}\"]\n",
    "                for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "        }\n",
    "\n",
    "    )\n",
    "        \n",
    "    #save and upload your model\n",
    "    accelerator.wait_for_everyone() #many processes\n",
    "    unwrapped_model = accelerator.unwrap_model(model) #start from scratch\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    \n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        repo.push_to_hub(commit_message=f\"Training in progress epoch {epoch}\", blocking=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f58051-f2f2-4c5b-a99a-098d2b015aa1",
   "metadata": {},
   "source": [
    "## 11. Inference!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d0bf06d-50d4-4042-afbe-8dcdebd55c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e465d2d37e4d68966b0aba4d6eb94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9557769fc6bd4f12b97a6c6c9dd636fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/431M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cff58bca804e4ca1321f9e1c6e8ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f213c10c05b4e17be2a15f6462f7649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6fc59130828473cbbcbebef3d23585e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/669k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df4a27f5e324e0a98a9553e3a5328bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "checkpoint = \"Chaklam/bert-finetuned-ner-accelerate\"\n",
    "\n",
    "clf        = pipeline(\"token-classification\", model=checkpoint, aggregation_strategy=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c861e278-30a8-4162-95a9-c1458ceefa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9725842,\n",
       "  'word': 'Ayush',\n",
       "  'start': 0,\n",
       "  'end': 5},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.98298603,\n",
       "  'word': 'Chaklam',\n",
       "  'start': 10,\n",
       "  'end': 17},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.7392455,\n",
       "  'word': 'AIT',\n",
       "  'start': 52,\n",
       "  'end': 55},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99720275,\n",
       "  'word': 'Bangkok',\n",
       "  'start': 57,\n",
       "  'end': 64},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9977047,\n",
       "  'word': 'Thailand',\n",
       "  'start': 66,\n",
       "  'end': 74}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(\"Ayush and Chaklam are going to play soccer today at AIT, Bangkok, Thailand and eat some snacks\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
